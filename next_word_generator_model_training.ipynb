{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Next Text generator\n",
        "This model is trained from from text taken from wikipedia (space theme )  so output are biased to that."
      ],
      "metadata": {
        "id": "DUk2VN6HYLGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --quiet\n"
      ],
      "metadata": {
        "id": "ytR4DDoUcXlO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import re, requests\n",
        "from collections import Counter\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "IPPvA1PmcoG2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests       #use download file\n",
        "url = \"https://raw.githubusercontent.com/kamalmalikofficial/next_word_finder/refs/heads/main/solarsys%20%26%20Earth.txt\"\n",
        "# 👆 is the text file from my github\n",
        "\n",
        "text = requests.get(url).text\n",
        "text = text * 15  # increase the same text count for confident learning\n",
        "\n",
        "print(\"Text length: \",    f\"{len(text)}\"   ,\"characters\")\n",
        "print(\"This is approx \",  f\"{len(text)/1024:.1f}\"  ,\"KB\")\n",
        "print(text[:500]) # use to print first 500 word just for confirmation\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTWohH2Bc4Ff",
        "outputId": "64199245-621c-43cf-b515-0ec7dc052d41"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text length:  2182950 characters\n",
            "This is approx  2131.8 KB\n",
            "Have you ever looked up at the night sky and wondered what's out there? Space is absolutely \r\n",
            "massive, beyond anything we can really imagine. The universe contains billions of galaxies, \r\n",
            "and each galaxy has billions of stars. It's mind-blowing when you think about it.\r\n",
            "Our solar system is pretty amazing too. The Sun sits at the center, and it's huge compared \r\n",
            "to Earth. You could fit over a million Earths inside the Sun. It's basically a giant ball \r\n",
            "of burning gas, mostly hydrogen and helium. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HjdweQ4wAgE",
        "outputId": "2f1edad3-426d-4ade-e7c8-eeec080b1cab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext\n",
            "  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext) (2.32.4)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from torchtext) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0->torchtext) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.3.0->torchtext) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.3.0->torchtext) (3.0.3)\n",
            "Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchtext\n",
            "Successfully installed torchtext-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# simple tokenizer (like torchtext basic_english)\n",
        "def simple_tokenizer(text):\n",
        "    return re.findall(r\"\\b\\w+\\b\", text.lower())\n",
        "\n",
        "tokens = simple_tokenizer(text)\n",
        "\n",
        "# build vocab\n",
        "def build_vocab(tokens, max_size=2000):\n",
        "    counts = Counter(tokens)\n",
        "    most_common = counts.most_common(max_size - 1)\n",
        "    vocab = {word: i + 1 for i, (word, _) in enumerate(most_common)}\n",
        "    vocab[\"<unk>\"] = 0\n",
        "    return vocab\n",
        "\n",
        "vocab = build_vocab(tokens)\n",
        "\n",
        "# encode text\n",
        "def encode(tokens, vocab):\n",
        "    return [vocab.get(token, 0) for token in tokens]\n",
        "\n",
        "encoded = encode(tokens, vocab)\n",
        "\n",
        "# create input-output pairs (predict next token)\n",
        "seq_len = 20\n",
        "data = []\n",
        "for i in range(len(encoded) - seq_len):\n",
        "    x = encoded[i:i + seq_len]\n",
        "    y = encoded[i + seq_len]\n",
        "    data.append((x, y))\n"
      ],
      "metadata": {
        "id": "jPKLAbVUwct6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (word, idx) in enumerate(vocab.items()):\n",
        "    print(f\"{word:10} → {idx}\")\n",
        "    if i == 20:  # just first 20 entries\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uNdayZrwl3i",
        "outputId": "75806bb9-7b77-4d3e-8ed3-d3be70ddbecf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the        → 1\n",
            "of         → 2\n",
            "and        → 3\n",
            "is         → 4\n",
            "to         → 5\n",
            "earth      → 6\n",
            "a          → 7\n",
            "in         → 8\n",
            "s          → 9\n",
            "sun        → 10\n",
            "are        → 11\n",
            "solar      → 12\n",
            "it         → 13\n",
            "as         → 14\n",
            "with       → 15\n",
            "that       → 16\n",
            "system     → 17\n",
            "from       → 18\n",
            "by         → 19\n",
            "at         → 20\n",
            "its        → 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use to do train_test_split to check validation and accuracy\n",
        "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
        "\n",
        "# suppose like data is list of (x, y) pairs\n",
        "X = torch.tensor([x for x, _ in data], dtype=torch.long)\n",
        "Y = torch.tensor([y for _, y in data], dtype=torch.long)\n",
        "\n",
        "dataset = TensorDataset(X, Y)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])  # to superrandonly split the data\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=64)\n"
      ],
      "metadata": {
        "id": "8EzhzlZj02Ls"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TinyNextWordModel(nn.Module):\n",
        "    def __init__(self, vocab_size=2000, embed_dim=32, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        out, _ = self.gru(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "vocab_size = min(len(vocab), 2000)\n",
        "model = TinyNextWordModel(vocab_size)\n",
        "\n",
        "print(\"Total trainable params:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO77Oeqnw6ZJ",
        "outputId": "68d013d0-cd75-4515-e9d7-e45f38fa2609"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total trainable params: 212816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()  # instead of mse cause treats word id like no.\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3) # adam is the most commanly used optimizer in dl\n",
        "epochs = 20   # this is the no. of epochs or no. of time we improve our result or decrese out loss function\n",
        "for epoch in range(epochs):\n",
        "    # main training code\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(xb)\n",
        "        loss = criterion(out, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "    # for validation\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            out = model(xb)\n",
        "            loss = criterion(out, yb)\n",
        "            total_val_loss += loss.item()\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCw3CGhDxB2l",
        "outputId": "4a3168d8-7dfb-40cb-a585-25ce0ce84847"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 4.8248, Val Loss = 3.9268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the entire model into pkl file cause the above code take 20 min to train\n",
        "torch.save(model, \"trained_model.pkl\")\n",
        "print(\"model saved\")\n"
      ],
      "metadata": {
        "id": "9yaiVT3laZrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# use to do the dict mapping inverse\n",
        "inv_vocab = {idx: word for word, idx in vocab.items()}\n",
        "\n",
        "def predict_topk(model, text_input, seq_len=20, top_k=5):\n",
        "    model.eval()\n",
        "    tokens = simple_tokenizer(text_input)  # same tokenizer as training\n",
        "    encoded = [vocab.get(t, 0) for t in tokens[-seq_len:]]\n",
        "    if len(encoded) < seq_len:\n",
        "        encoded = [0]*(seq_len - len(encoded)) + encoded\n",
        "    x = torch.tensor(encoded).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model(x)\n",
        "        probs = F.softmax(out, dim=1)\n",
        "        top_probs, top_idxs = probs.topk(top_k, dim=1)\n",
        "\n",
        "    results = [(inv_vocab.get(idx.item(), \"unknown\"), prob.item())\n",
        "               for idx, prob in zip(top_idxs[0], top_probs[0])]\n",
        "    return results"
      ],
      "metadata": {
        "id": "aF0PQrMs4Fmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "otnb7UfV4mAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1__GemXgcdUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = predict_topk(model, \" black \", top_k=5)\n",
        "for word, prob in preds:\n",
        "    print(f\"{word:10s} — {prob:.2f}\")\n"
      ],
      "metadata": {
        "id": "fsLBukhF4Zd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(vocab, \"vocab.pkl\")\n"
      ],
      "metadata": {
        "id": "gEreEe144caG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(inv_vocab, \"inv_vocab.pkl\")"
      ],
      "metadata": {
        "id": "E-tjvv-Wkg4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I20-MkBknEuR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}